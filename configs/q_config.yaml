# Configuration for the Quantum-Enhanced LSTM Model
project: "demand_forecasting"
experiment_name: "QEnhancedLSTM_experiment"

# --- Data Configuration ---
target_column: "Demand(MW)"
forecasting_type: "univariate" # Or multivariate
features: [] 
sequence_length: 24
forecast_horizon: 1
test_size: 0.2
val_size: 0.2
random_state: 42

# --- Model Configuration ---
model_type: "QEnhancedLSTM"

# Classical Part Parameters
classical_lstm_hidden_size: 4  # IMPORTANT: For this simple model, this should match n_qubits
num_classical_lstm_layers: 1   # Number of LSTM layers

# Quantum Part Parameters
n_qubits: 4                    # Number of qubits in the quantum circuit
n_quantum_layers: 2            # Number of trainable layers in the VQC

# Common Parameters
input_size: 1                  # Auto-set by preprocessing
dropout: 0.1

# --- Training Configuration ---
batch_size: 8   # Quantum simulations are slow, so smaller batches are recommended
learning_rate: 0.01 # Quantum models often benefit from larger learning rates
num_epochs: 30
patience: 10
checkpoint_freq: 5

# --- W&B Configuration ---
use_wandb: True
wandb_project: "demand_forecasting_quantum"
wandb_entity: null
